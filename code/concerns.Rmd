---
title: "Concerns"
author: "Laura"
date: "2/9/2021"
output:
  word_document: default
  html_document: default
---

```{r setup, echo = FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message = FALSE, error=FALSE)
```

```{r, packages}
library(tidyverse)
library(lubridate)
library(knitr)
library(grDevices)
library(extrafont)
library(ggrepel)
library(ggthemes)
library(gridExtra)
library(likert)
library(ggbiplot)
library(GGally)
library(PNWColors)
library(ggpubr)
library(reshape2)
library(factoextra)
library(NbClust)
library(car)
library(ggplot2)
library(ggdendro)
library(car)

# windowsFonts(Times=windowsFont("Calibri"))
theme_sleek <- function(base_size = 12, base_family = "Calibri") {
  half_line <- base_size/2
  theme_light(base_size = 12, base_family = "Calibri") +
    theme(
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(),
      axis.ticks.length = unit(half_line / 2.2, "pt"),
      strip.background = element_rect(fill = NA, colour = NA),
      strip.text.x = element_text(colour = "black"),
      strip.text.y = element_text(colour = "black"),
      # axis.text = element_text(colour = "grey30"),
      #axis.title = element_text(colour = "grey30"),
      #legend.title = element_text(colour = "grey30"),#, size = rel(0.9)
      legend.title = element_blank(),
      panel.border = element_rect(fill = NA),#, colour = "grey70", size = 1),
      legend.key.size = unit(0.9, "lines"),
      #legend.text = element_text(size = rel(0.7)),#, colour = "grey30"),
      legend.key = element_rect(colour = NA, fill = NA),
      legend.background = element_rect(colour = NA, fill = NA)#,
      #plot.title = element_text(colour = "grey30"),#, size = rel(1),
      #plot.subtitle = element_text(colour = "grey30")#, size = rel(.85),
     
      
    )
}
theme_set(theme_sleek())
options(scipen = 999) #turns off scientific notation
# Depends on dplyr
tickr <- function(
  data, # dataframe
  var, # column of interest
  to # break point definition 
){
  
  VAR <- enquo(var) # makes VAR a dynamic variable
  
  data %>% 
    distinct(!!VAR) %>%
    ungroup(!!VAR) %>% 
    mutate(labels = ifelse(!!VAR %in% seq(to * round(min(!!VAR) / to), max(!!VAR), to),
                           !!VAR, "")) %>%
    select(breaks = UQ(VAR), labels)
}
```

```{r load data}
responses <- read.csv("../data/PNW_decoded_vulnerability.csv")
```
```{r}
#color paletes

pal3<-pnw_palette(name="Sailboat",n=3,type="discrete")
pal4<-pnw_palette(name="Sailboat",n=4,type="discrete")
pal5<-pnw_palette(name="Sailboat",n=5,type="discrete")
pal6<-pnw_palette(name="Sailboat",n=6,type="discrete")
pal7<-pnw_palette(name="Sailboat",n=7,type="continuous")

```
#concerns table
#responses from questions 33-36 about issues that may affect fishing success and wellbeing
#grouped into categories following the survey: marine environment, fishing operations, community and infrastructure, and personal
```{r}

worries<-responses %>%
  select(warming_concern, oa_concern, storm_concern, sea_level_concern, weather_concern, h20_quality_concern, algal_concern, habitat_concern, pop_size_concern, bycatch_concern, value_concern, costs_concern, sa_concern, distance_concern, reg_concern, graying_fleet_concern, fish_comm_concern, resid_concern, infrastructure_concern, phsy_health_concern, mental_health_concern, safe_at_sea_concern, family_concern, think_warming, think_oa, think_storm, think_sea_level, think_weather, think_h20_quality, think_algal, think_habitat, think_pop_size, think_bycatch, think_value, think_costs, think_sa, think_distance, think_reg, think_graying_fleet, think_fish_comm, think_resid, think_infrastructure, think_phsy_health, think_mental_health, think_safe_at_sea, think_family)
```

#function for numberic worry scale
```{r}
worry_calc <- function(x){
if(is.na(x)){
  return("NA")
} else if(x == "none"){
  return(1)
} else if(x == "somewhat"){
  return(2)
} else if(x == "very"){
  return(3)
}
}

freq_calc <- function(x){
if(is.na(x)){
  return("NA")
} else if(x == "never"){
  return(1)
} else if(x == "occasionally"){
  return(2)
} else if(x == "frequently"){
  return(3)
}
}
```

#giving numberic values to responses
```{r}
worries <- worries %>% 
  mutate(warming_concern = sapply(X=worries$warming_concern, FUN=worry_calc),
         oa_concern = sapply(X=worries$oa_concern, FUN=worry_calc),
         storm_concern = sapply(X=worries$storm_concern, FUN=worry_calc),
         sea_level_concern = sapply(X=worries$sea_level_concern, FUN=worry_calc),
         weather_concern = sapply(X=worries$weather_concern, FUN=worry_calc),
         h20_quality_concern = sapply(X=worries$h20_quality_concern, FUN=worry_calc),
         algal_concern = sapply(X=worries$algal_concern, FUN=worry_calc),
         habitat_concern = sapply(X=worries$habitat_concern, FUN=worry_calc),
         pop_size_concern = sapply(X=worries$pop_size_concern, FUN=worry_calc),
         bycatch_concern = sapply(X=worries$bycatch_concern, FUN=worry_calc),
         value_concern = sapply(X=worries$value_concern, FUN=worry_calc),
         costs_concern = sapply(X=worries$costs_concern, FUN=worry_calc),
         sa_concern = sapply(X=worries$sa_concern, FUN=worry_calc),
         distance_concern = sapply(X=worries$distance_concern, FUN=worry_calc),
         reg_concern = sapply(X=worries$reg_concern, FUN=worry_calc),
         graying_fleet_concern = sapply(X=worries$graying_fleet_concern, FUN=worry_calc),
         fish_comm_concern = sapply(X=worries$fish_comm_concern, FUN=worry_calc),
         resid_concern = sapply(X=worries$resid_concern, FUN=worry_calc),
         infrastructure_concern = sapply(X=worries$infrastructure_concern, FUN=worry_calc),
         phsy_health_concern = sapply(X=worries$phsy_health_concern, FUN=worry_calc),
         mental_health_concern = sapply(X=worries$mental_health_concern, FUN=worry_calc),
         safe_at_sea_concern = sapply(X=worries$safe_at_sea_concern, FUN=worry_calc),
         family_concern = sapply(X=worries$family_concern, FUN=worry_calc),
         think_warming = sapply(X=think_warming, FUN = freq_calc),
         think_oa = sapply(X=think_oa, FUN = freq_calc),
         think_storm = sapply(X=think_storm, FUN = freq_calc),
         think_sea_level = sapply(X=think_sea_level, FUN = freq_calc),
         think_weather = sapply(X=think_weather, FUN = freq_calc),
         think_h20_quality = sapply(X=think_h20_quality, FUN = freq_calc),
         think_algal = sapply(X=think_algal, FUN = freq_calc),
         think_habitat = sapply(X=think_habitat, FUN = freq_calc), 
         think_pop_size = sapply(X=think_pop_size, FUN = freq_calc), 
         think_bycatch = sapply(X=think_bycatch, FUN = freq_calc), 
         think_value = sapply(X=think_value, FUN = freq_calc), 
         think_costs = sapply(X=think_costs, FUN = freq_calc), 
         think_sa = sapply(X=think_sa, FUN = freq_calc), 
         think_distance = sapply(X=think_distance, FUN = freq_calc), 
         think_reg = sapply(X=think_reg, FUN = freq_calc), 
         think_graying_fleet = sapply(X=think_graying_fleet, FUN = freq_calc), 
         think_fish_comm = sapply(X=think_fish_comm, FUN = freq_calc), 
         think_resid = sapply(X=think_resid, FUN = freq_calc), 
         think_infrastructure = sapply(X=think_infrastructure, FUN = freq_calc), 
         think_phsy_health = sapply(X=think_phsy_health, FUN = freq_calc), 
         think_mental_health = sapply(X=think_mental_health, FUN = freq_calc), 
         think_safe_at_sea = sapply(X=think_safe_at_sea, FUN = freq_calc), 
         think_family = sapply(X=think_family, FUN = freq_calc))
```

#correlation matrix of concern answers
```{r}

just_concerns<-worries[,1:23]

colnames(just_concerns)<-c("warming", "oa", "storm", "sea_level", "weather", "h20_quality", "HABs", "habitat", "pop_size", "bycatch", "value", "costs", "stock_assess", "distance", "regs", "graying_fleet", "fishing_comm", "resid_comm", "infrastructure", "phsy_health", "mental_health", "safe_at_sea", "family")

#first pearson
concerns_correlation<-cor(just_concerns)
concerns_correlation

worry_cor_plot<-ggcorr(just_concerns)

ggsave(plot = worry_cor_plot, file = paste0("../figures/wellbeing/worry_cor.png"))

#check what spearman says
concerns_correlation_sp<-cor(just_concerns, method = "spearman")
concerns_correlation_sp
```


#group by category
```{r}
me<-worries %>%
  select(warming_concern, oa_concern, storm_concern, sea_level_concern, weather_concern, h20_quality_concern, algal_concern, habitat_concern, think_warming, think_oa, think_storm, think_sea_level, think_weather, think_h20_quality, think_algal, think_habitat)

fo<-worries %>%
  select(pop_size_concern, bycatch_concern, value_concern, costs_concern, sa_concern, distance_concern, reg_concern, think_pop_size, think_bycatch, think_value, think_costs, think_sa, think_distance, think_reg)

comin <- worries %>%
  select(graying_fleet_concern, fish_comm_concern, resid_concern, infrastructure_concern,think_graying_fleet, think_fish_comm, think_resid, think_infrastructure)

per<- worries %>%
  select(phsy_health_concern, mental_health_concern, safe_at_sea_concern, family_concern, think_phsy_health, think_mental_health, think_safe_at_sea, think_family)
```
#score for each category
#average of responses for the questions in each category
#weighted by frequency of thought
```{r}
#marine environment
me$marine_env = as.numeric(NA, length(nrow(me)))

me<-me %>%
  mutate(marine_env = (warming_concern*think_warming + 
        oa_concern*think_oa + 
        storm_concern*think_storm +
        sea_level_concern*think_sea_level +
        weather_concern*think_weather +
        h20_quality_concern*think_h20_quality +
        algal_concern*think_algal +
        habitat_concern*think_habitat)/8)

worries$marine_env = me$marine_env

#fishing operations
fo$fishing_ops = as.numeric(NA, length(nrow(fo)))

fo<-fo %>%
  mutate(fishing_ops = 
           (pop_size_concern*think_pop_size +
           bycatch_concern*think_bycatch +
           value_concern*think_value +
           costs_concern*think_costs +
           sa_concern*think_sa +
           distance_concern*think_distance +
           reg_concern*think_reg)/7)

worries$fishing_ops = fo$fishing_ops

#community and infrastructure
comin$community_infras = as.numeric(NA, length(nrow(comin)))

comin <- comin %>%
  mutate(community_infras = 
           (graying_fleet_concern*think_graying_fleet +
           fish_comm_concern*think_fish_comm +
           resid_concern*think_resid +
           infrastructure_concern*think_infrastructure)/4)

worries$community_infras = comin$community_infras

#personal
per$personal = as.numeric(NA, length(nrow(per)))

per<-per %>%
  mutate(personal =
           (phsy_health_concern*think_phsy_health +
           mental_health_concern*think_mental_health +
           safe_at_sea_concern*think_safe_at_sea +
           family_concern*think_family)/4)

worries$personal = per$personal
```

#two other themes of concern on different likert scales
#outlook - question 37, and sense of conflict - question 38
```{r}

#function for 5 level likert scale
five_likert <- function(x){
if(is.na(x)){
  return("NA")
} else if(x == "strongly_disagree"){
  return(1)
} else if(x == "somewhat_disagree"){
  return(2)
} else if(x == "neutral"){
  return(3)
} else if(x == "somewhat_agree"){
  return(4)
} else if(x == "strongly_agree"){
  return(5)
}
}

#gather responses to questions 37 and 38 to make numeric
oandc<-responses %>%
  select(believe, harm_me, harm_future, leave_fishing, risk, no_point, no_fish, recreational, other_fishery, internal, aquaculture, hatcheries, tourism, development, spatial)

oandc <- oandc %>% 
  mutate(believe = sapply(X=believe, FUN=five_likert),
        harm_me = sapply(X=harm_me, FUN=five_likert),
        harm_future = sapply(X=harm_future, FUN=five_likert),
        leave_fishing = sapply(X=leave_fishing, FUN=five_likert),
        risk = sapply(X=risk, FUN=five_likert),
        no_point = sapply(X=no_point, FUN=five_likert),
        no_fish = sapply(X=no_fish, FUN=five_likert),
        recreational = sapply(X=recreational, FUN=five_likert),
        other_fishery = sapply(X=other_fishery, FUN=five_likert),
        internal = sapply(X=internal, FUN=five_likert),
        aquaculture = sapply(X=aquaculture, FUN=five_likert),
        hatcheries = sapply(X=hatcheries, FUN=five_likert),
        tourism = sapply(X=tourism, FUN=five_likert),
        development = sapply(X=development, FUN=five_likert),
        spatial = sapply(X=spatial, FUN=five_likert))

oandc$outlook = as.numeric(NA, length(nrow(oandc)))
oandc$conflict = as.numeric(NA, length(nrow(oandc)))

oandc <- oandc %>%
  mutate(outlook = (believe + harm_me + harm_future + leave_fishing + risk + no_point + no_fish)/7)

oandc <- oandc %>%
  mutate(conflict = (recreational + other_fishery + internal + aquaculture + hatcheries + tourism + development + spatial)/8)

worries$outlook = oandc$outlook
worries$conflict = oandc$conflict
```

#check for correlation between concern categories
```{r}
concern_scores<- worries %>%
  select(marine_env, fishing_ops, community_infras, personal, outlook, conflict)

#check for colinearity between categories
cor(concern_scores, method = "spearman")
cor(concern_scores)

concern_themes_plot<-ggcorr(concern_scores)
concern_themes_plot

ggsave(plot = concern_themes_plot, file = paste0("../figures/wellbeing/concern_themes_cor.png"))
```
##clustering and rescaling can occur a few different ways
##first follow example from lui et al

#rescale and cluster using max value for each theme
```{r}
#rescale from 0 to 1 by dividing each metric by maximum potential value
#max would be 5 for conflict and outlook
#max would be 9 for other concerns

concern_scores<- worries %>%
  select(marine_env, fishing_ops, community_infras, personal, outlook, conflict)

concern_scores_om <- concern_scores %>%
  mutate(marine_env = marine_env/9,
         fishing_ops = fishing_ops/9,
         community_infras = community_infras/9,
         personal = personal/9,
         outlook = outlook/5,
         conflict = conflict/5)

#concern_scores_om[,1:6]

#cluster
cluster_results<-NbClust(concern_scores_om[,1:6], distance = "euclidean", min.nc = 2, max.nc = 12, method = "complete", index = "alllong")

#recommends 3 clusters

#do the clustering
#heirachical with ward method
#computational costs = 4 mint milanos
d<-dist(concern_scores_om, method = "euclidean")
con_cluster<-hclust(d, method = "ward")
groups<-cutree(con_cluster, k=3)
concern_scores_om<-cbind(concern_scores_om, groups)
concern_scores_om$groups<-as.factor(concern_scores_om$groups)

responses$concern_groups = concern_scores_om$groups

plot(con_cluster)
```
#pca of concern answers
```{r}
colnames(concern_scores_om)<-c("environment", "fishing ops", "community and infrastructure", "personal", "outlook", "conflict", "groups")

concerns_pca<-prcomp(concern_scores_om[,1:6], scale = FALSE)
summary(concerns_pca)

concerns_pca$rotation
concerns_pca$x
str(concerns_pca)

#eigenvalues
eig_concern<-get_eig(concerns_pca)
eig_concern

fviz_eig(concerns_pca)

#results for variable
var_concern <- get_pca_var(concerns_pca)
var_concern$coord          # Coordinates
var_concern$contrib        # Contributions to the PCs
var_concern$cos2           # Quality of representation 

#biplot
#adjust color n to clusters
concerns_pca_plot<-ggbiplot(concerns_pca, ellipse = TRUE, groups = concern_scores_om$groups) +
  scale_color_manual(values = pnw_palette(n=3, name = "Bay"))+
  theme(legend.position = "bottom")

ggsave(plot = concerns_pca_plot, file = paste0("../figures/wellbeing/concern_pca_final.png"))

#screeplot of components
concerns_scree<-fviz_eig(concerns_pca)

concerns_variables<-fviz_pca_var(concerns_pca, repel = TRUE)

ggsave(plot = concerns_scree, file = paste0("../figures/wellbeing/concern_scree_final.png"))

ggsave(plot = concerns_variables, file = paste0("../figures/wellbeing/concern_variable_final.png"))

```
#rescale and cluster using the r scale method
```{r eval=FALSE, include=FALSE}

#rescale using R scale function

concern_scores_rescaled<-scale(concern_scores)
concern_scores_rescaled<-as.data.frame(concern_scores_rescaled)

#cluster
NbClust(concern_scores_rescaled, distance = "euclidean", min.nc = 2, max.nc = 10, method = "complete", index = "alllong")

#recommends 2 clusters when done this way

#do the clustering
#computational costs = 4 mint milanos
d<-dist(concern_scores_rescaled, method = "euclidean")
con_cluster<-hclust(d, method = "ward")
groups<-cutree(con_cluster, k=2)
concern_scores_rescaled<-cbind(concern_scores_rescaled, groups)
concern_scores_rescaled$groups<-as.factor(concern_scores_rescaled$groups)

plot(con_cluster, leaflab = "none")

```

#pca of concern answers using r rescale
```{r eval=FALSE, include=FALSE}
colnames(concern_scores_om)<-c("environment", "fishing_ops", "community_and_infrastructure", "personal", "outlook", "conflict", "groups")

concerns_rsc_pca<-prcomp(concern_scores_rescaled[,1:6], scale = FALSE)
summary(concerns_rsc_pca)

#eigenvalues
eig_concern_rsc<-get_eig(concerns_rsc_pca)
eig_concern_rsc

#results for variable
var_concern_rsc <- get_pca_var(concerns_rsc_pca)
var_concern_rsc$coord          # Coordinates
var_concern_rsc$contrib        # Contributions to the PCs
var_concern_rsc$cos2           # Quality of representation 

pal<-pnw_palette(name="Bay", n=3, type = "discrete")
concerns_rsc_pca_plot<-ggbiplot(concerns_rsc_pca, ellipse = TRUE, groups = concern_scores_rescaled$groups) +
  scale_color_manual(values = pnw_palette(n=2, name = "Bay"))+
  theme(legend.position = "bottom")

ggsave(plot = concerns_rsc_pca_plot, file = paste0("../figures/wellbeing/concern_rsc_pca.png"))

#screeplot of components
concerns_rsc_scree<-fviz_eig(concerns_rsc_pca)

concerns_rsc_variables<-fviz_pca_var(concerns_rsc_pca, repel = TRUE)

ggsave(plot = concerns_rsc_scree, file = paste0("../figures/wellbeing/concern_rsc_scree.png"))

ggsave(plot = concerns_rsc_variables, file = paste0("../figures/wellbeing/concern_rsc_variable.png"))
```

##plot with colors corresponding to contribution to dimensions
```{r}

fviz_pca_var(concerns_pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
             )

fviz_pca_var(test.concern.pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
             )


```


#checking out variable values across clusters
#series of box plots for each category of concern
```{r}
envir_bp<-ggboxplot(concern_scores_om, x = "groups", y ="environment",
                    fill = "groups", palette = pal3)

fishops_bp<-ggboxplot(concern_scores_om, x = "groups", y ="fishing ops",
                    fill = "groups", palette = pal3)

candi_bp<-ggboxplot(concern_scores_om, x = "groups", y ="community and infrastructure",
                    fill = "groups", palette = pal3)

personal_bp<-ggboxplot(concern_scores_om, x = "groups", y ="personal",
                    fill = "groups", palette = pal3)

outlook_bp<-ggboxplot(concern_scores_om, x = "groups", y ="outlook",
                    fill = "groups", palette = pal3)

conflict_bp<-ggboxplot(concern_scores_om, x = "groups", y ="conflict",
                    fill = "groups", palette = pal3)

concerns_by_cluster_plot<-grid.arrange(envir_bp, fishops_bp, candi_bp, personal_bp, outlook_bp, conflict_bp, nrow = 2, top = "Concerns by cluster")

concerns_by_cluster_plot

cbc_long<-melt(concern_scores_om)

cbc_plot<-ggplot(cbc_long, aes(x=groups, y = value, fill = groups)) + geom_boxplot()+
  facet_wrap(~variable, scale = "free")+
  scale_fill_manual(values = pnw_palette(n=3, name = "Sailboat"))

cbc_plot

ggsave(plot = cbc_plot, height = 7, width = 10, file = paste0("../figures/wellbeing/concern_3_cluster.png"))
```



#box plot not rescaled
```{r}
concern_scores$groups = concern_scores_rescaled$groups

cbc_long2<-melt(concern_scores)

cbc_plot2<-ggplot(cbc_long2, aes(x=groups, y = value, fill = groups)) + geom_boxplot()+
  facet_wrap(~variable, scale = "free")+
  scale_fill_manual(values = pnw_palette(n=3, name = "Bay"))

cbc_plot2

ggsave(plot = cbc_plot, file = paste0("../figures/wellbeing/concern_by_cluster3.png"))
```

##anova and tukey between clusters and themes to check for differences
#marine environment
```{r}
en.av<-aov(environment ~ groups, data = concern_scores_om)
summary(en.av)

TukeyHSD(en.av)

#test anova assumptions
#homogenity of variance
#levene test for homogenity of variance
leveneTest(environment ~ groups, data = concern_scores_om)

#Normality
plot(en.av, 2)

#shapiro-wilk test to test for normality
# Extract the residuals
aov_residuals <- residuals(object = en.av)
# Run Shapiro-Wilk test
shapiro.test(x = aov_residuals)

#variance is not homogenious but normality is fine
#use welch one way test and pairwise t-test

oneway.test(environment ~ groups, data = concern_scores_om)

pairwise.t.test(concern_scores_om$environment, concern_scores_om$groups,
                 p.adjust.method = "BH", pool.sd = FALSE)

pairwise.t.test(concern_scores_om$environment, concern_scores_om$groups,
                 p.adjust.method = "bonferroni", pool.sd = FALSE)

pairwise.t.test(concern_scores_om$environment, concern_scores_om$groups,
                 p.adjust.method = "none", pool.sd = FALSE)
```
##fishing operations
```{r}
fo.av<-aov(concern_scores_om[,2] ~ groups, data = concern_scores_om)
summary(fo.av)

TukeyHSD(fo.av)

#test anova assumptions
#homogenity of variance
#levene test for homogenity of variance
leveneTest(concern_scores_om[,2] ~ groups, data = concern_scores_om)

#Normality
plot(fo.av, 2)

#shapiro-wilk test to test for normality
# Extract the residuals
aov_residuals <- residuals(object = fo.av)
# Run Shapiro-Wilk test
shapiro.test(x = aov_residuals)

#variance is not homogenious but normality is fine
#use welch one way test and pairwise t-test

oneway.test(concern_scores_om[,2] ~ groups, data = concern_scores_om)

pairwise.t.test(concern_scores_om[,2], concern_scores_om$groups,
                 p.adjust.method = "BH", pool.sd = FALSE)

pairwise.t.test(concern_scores_om[,2], concern_scores_om$groups,
                 p.adjust.method = "bonferroni", pool.sd = FALSE)
```
##community and infrastructure
```{r}
cai.av<-aov(concern_scores_om[,3] ~ groups, data = concern_scores_om)
summary(cai.av)

TukeyHSD(cai.av)

#test anova assumptions
#homogenity of variance
#levene test for homogenity of variance
leveneTest(concern_scores_om[,3] ~ groups, data = concern_scores_om)

#Normality
plot(cai.av, 2)

#shapiro-wilk test to test for normality
# Extract the residuals
aov_residuals <- residuals(object = cai.av)
# Run Shapiro-Wilk test
shapiro.test(x = aov_residuals)

#variance is not homogenious but normality is fine
#use welch one way test and pairwise t-test

oneway.test(concern_scores_om[,3] ~ groups, data = concern_scores_om)

pairwise.t.test(concern_scores_om[,3], concern_scores_om$groups,
                 p.adjust.method = "BH", pool.sd = FALSE)

pairwise.t.test(concern_scores_om[,3], concern_scores_om$groups,
                 p.adjust.method = "bonferroni", pool.sd = FALSE)
```

##personal
```{r}
per.av<-aov(concern_scores_om[,4] ~ groups, data = concern_scores_om)
summary(per.av)

TukeyHSD(per.av)

#test anova assumptions
#homogenity of variance
#levene test for homogenity of variance
leveneTest(concern_scores_om[,4] ~ groups, data = concern_scores_om)

#Normality
plot(per.av, 2)

#shapiro-wilk test to test for normality
# Extract the residuals
aov_residuals <- residuals(object = per.av)
# Run Shapiro-Wilk test
shapiro.test(x = aov_residuals)

#variance is not homogenious but normality is fine
#use welch one way test and pairwise t-test

oneway.test(concern_scores_om[,4] ~ groups, data = concern_scores_om)

pairwise.t.test(concern_scores_om[,4], concern_scores_om$groups,
                 p.adjust.method = "BH", pool.sd = FALSE)

pairwise.t.test(concern_scores_om[,4], concern_scores_om$groups,
                 p.adjust.method = "bonferroni", pool.sd = FALSE)
```

##outlook
```{r}
con.av<-aov(concern_scores_om[,5] ~ groups, data = concern_scores_om)
summary(con.av)

TukeyHSD(con.av)

#test anova assumptions
#homogenity of variance
#levene test for homogenity of variance
leveneTest(concern_scores_om[,5] ~ groups, data = concern_scores_om)

#Normality
plot(con.av, 2)

#shapiro-wilk test to test for normality
# Extract the residuals
aov_residuals <- residuals(object = con.av)
# Run Shapiro-Wilk test
shapiro.test(x = aov_residuals)

#variance is not homogenious but normality is fine
#use welch one way test and pairwise t-test

oneway.test(concern_scores_om[,5] ~ groups, data = concern_scores_om)

pairwise.t.test(concern_scores_om[,5], concern_scores_om$groups,
                 p.adjust.method = "BH", pool.sd = FALSE)
pairwise.t.test(concern_scores_om[,5], concern_scores_om$groups,
                 p.adjust.method = "bonferroni", pool.sd = FALSE)

kruskal.test(concern_scores_om[,5] ~ groups, data = concern_scores_om)
```

##conflict
```{r}
out.av<-aov(concern_scores_om[,6] ~ groups, data = concern_scores_om)
summary(out.av)

TukeyHSD(out.av)

#test anova assumptions
#homogenity of variance
#levene test for homogenity of variance
leveneTest(concern_scores_om[,6] ~ groups, data = concern_scores_om)

#Normality
plot(out.av, 2)

#shapiro-wilk test to test for normality
# Extract the residuals
aov_residuals <- residuals(object = out.av)
# Run Shapiro-Wilk test
shapiro.test(x = aov_residuals)

#variance is not homogenious but normality is fine
#use welch one way test and pairwise t-test

oneway.test(concern_scores_om[,6] ~ groups, data = concern_scores_om)

pairwise.t.test(concern_scores_om[,6], concern_scores_om$groups,
                 p.adjust.method = "BH", pool.sd = FALSE)
pairwise.t.test(concern_scores_om[,6], concern_scores_om$groups,
                 p.adjust.method = "bonferroni", pool.sd = FALSE)

kruskal.test(concern_scores_om[,6] ~ groups, data = concern_scores_om)
```
```
aov('fishing ops' ~ groups, data = concern_scores_rescaled)
aov('community and infrastructure' ~ groups, data = concern_scores_rescaled)
aov(personal ~ groups, data = concern_scores_rescaled)
aov(conflict ~ groups, data = concern_scores_rescaled)
aov(outlook ~ groups, data = concern_scores_rescaled)

#test anova assumptions
#levene test for homogenity of variance
leveneTest(environment ~ groups, data = concern_scores_rescaled)
leveneTest('fishing ops' ~ groups, data = concern_scores_rescaled)
leveneTest('community and infrastructure' ~ groups, data = concern_scores_rescaled)
leveneTest(personal ~ groups, data = concern_scores_rescaled)
leveneTest(conflict ~ groups, data = concern_scores_rescaled)
leveneTest(outlook ~ groups, data = concern_scores_rescaled)
```

#two other themes of concern on different likert scales
#outlook - question 37, and sense of conflict - question 38
```{r}

#function for 5 level likert scale
#do it from 1 to 9 so it matches the scale of the other question
five_likert <- function(x){
if(is.na(x)){
  return("NA")
} else if(x == "strongly_disagree"){
  return(1)
} else if(x == "somewhat_disagree"){
  return(3)
} else if(x == "neutral"){
  return(5)
} else if(x == "somewhat_agree"){
  return(7)
} else if(x == "strongly_agree"){
  return(9)
}
}

#gather responses to questions 37 and 38 to make numeric
oandc.2<-responses %>%
  select(believe, harm_me, harm_future, leave_fishing, risk, no_point, no_fish, recreational, other_fishery, internal, aquaculture, hatcheries, tourism, development, spatial)

oandc.2 <- oandc.2 %>% 
  mutate(believe = sapply(X=believe, FUN=five_likert),
        harm_me = sapply(X=harm_me, FUN=five_likert),
        harm_future = sapply(X=harm_future, FUN=five_likert),
        leave_fishing = sapply(X=leave_fishing, FUN=five_likert),
        risk = sapply(X=risk, FUN=five_likert),
        no_point = sapply(X=no_point, FUN=five_likert),
        no_fish = sapply(X=no_fish, FUN=five_likert),
        recreational = sapply(X=recreational, FUN=five_likert),
        other_fishery = sapply(X=other_fishery, FUN=five_likert),
        internal = sapply(X=internal, FUN=five_likert),
        aquaculture = sapply(X=aquaculture, FUN=five_likert),
        hatcheries = sapply(X=hatcheries, FUN=five_likert),
        tourism = sapply(X=tourism, FUN=five_likert),
        development = sapply(X=development, FUN=five_likert),
        spatial = sapply(X=spatial, FUN=five_likert))

oandc.2$outlook = as.numeric(NA, length(nrow(oandc.2)))
oandc.2$conflict = as.numeric(NA, length(nrow(oandc.2)))

oandc.2 <- oandc.2 %>%
  mutate(outlook = (believe + harm_me + harm_future + leave_fishing + risk + no_point + no_fish)/7)

oandc.2 <- oandc.2 %>%
  mutate(conflict = (recreational + other_fishery + internal + aquaculture + hatcheries + tourism + development + spatial)/8)

worries$outlook = oandc.2$outlook
worries$conflict = oandc.2$conflict
```

#check for correlation between concern categories
```{r}
concern_scores<- worries %>%
  select(marine_env, fishing_ops, community_infras, personal, outlook, conflict)

#check for colinearity between categories
cor(concern_scores, method = "spearman")
cor(concern_scores)

concern_themes_plot<-ggcorr(concern_scores)
concern_themes_plot

ggsave(plot = concern_themes_plot, file = paste0("../figures/wellbeing/concern_themes_cor3.png"))
```

#cluster
#shouldn't need to be rescaled since all 1 - 9
```{r}

#cluster
NbClust(concern_scores, distance = "euclidean", min.nc = 2, max.nc = 10, method = "complete", index = "alllong")

#recommends 4 clusters

#do the clustering
#computational costs = 4 mint milanos
d<-dist(concern_scores, method = "euclidean")
con_cluster<-hclust(d, method = "ward")
groups<-cutree(con_cluster, k=4)
concern_scores<-cbind(concern_scores, groups)
concern_scores$groups<-as.factor(concern_scores$groups)

plot(con_cluster)
ggdendrogram(con_cluster)

```

##pca using the 1-9 scaled scores
```{r}

take3<-prcomp(concern_scores[,1:6], scale = FALSE)
summary(take3)

#eigenvalues
eig_concern_test<-get_eig(take3)
eig_concern_test

#results for variable
var_take3 <- get_pca_var(take3)
var_take3$coord          # Coordinates
var_take3$contrib        # Contributions to the PCs
var_take3$cos2           # Quality of representation 

pal<-pnw_palette(name="Bay", n=4, type = "discrete")
take3_plot<-ggbiplot(take3, ellipse = TRUE, groups = concern_scores$groups) +
  scale_color_manual(values = pnw_palette(n=4, name = "Bay"))+
  theme(legend.position = "bottom")

take3_plot

ggsave(plot = take3_plot, file = paste0("../figures/wellbeing/concern_attempt3.png"))

#screeplot of components
concerns_scree3<-fviz_eig(take3)
concerns_scree3

concerns_variables3<-fviz_pca_var(take3, repel = TRUE)
concerns_variables3

ggsave(plot = concerns_scree3, file = paste0("../figures/wellbeing/concern_scree3.png"))

ggsave(plot = concerns_variables3, file = paste0("../figures/wellbeing/concern_variable3.png"))

#plot by contribution to components
fviz_pca_var(take3,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
             )

```

#box plot with 1-9 scale
```{r}

cbc_long3<-melt(concern_scores)

cbc_plot3<-ggplot(cbc_long3, aes(x=groups, y = value, fill = groups)) + geom_boxplot()+
  facet_wrap(~variable, scale = "free")+
  scale_fill_manual(values = pnw_palette(n=4, name = "Bay"))

cbc_plot3

ggsave(plot = cbc_plot3, file = paste0("../figures/wellbeing/concern_by_cluster3.png"))
```

#who is in which group?
```{r}
responses$concern_group = concern_scores$groups

table(responses$concern_group)

chisq.test(table(responses$concern_group, responses$state_code))
chisq.test(table(responses$concern_group, responses$age))
chisq.test(table(responses$concern_group, responses$yrs_fishing))
chisq.test(table(responses$concern_group, responses$yrs_residence))
chisq.test(table(responses$concern_group, responses$income))

responses %>% group_by(concern_group) %>%
  dplyr::summarise(n = n(),
            ex = mean(indv_exposure, na.rm =TRUE),
            sen = mean(indv_sensitivity, na.rm = TRUE),
            ac = mean(indv_ac),
            vuln = mean(indv_vulnerability_euc, na.rm = TRUE)
            )
  

```

##anova and tukey between clusters and themes to check for differences
##this is for the version scaled 1-9
#marine environment
```{r}
en.av<-aov(marine_env ~ groups, data = concern_scores)
summary(en.av)

TukeyHSD(en.av)

#test anova assumptions
#homogenity of variance
#levene test for homogenity of variance
leveneTest(marine_env ~ groups, data = concern_scores)

#Normality
plot(en.av, 2)

#shapiro-wilk test to test for normality
# Extract the residuals
aov_residuals <- residuals(object = en.av)
# Run Shapiro-Wilk test
shapiro.test(x = aov_residuals)

#variance is not homogenious but normality is fine
#use welch one way test and pairwise t-test

oneway.test(marine_env ~ groups, data = concern_scores)

pairwise.t.test(concern_scores$marine_env, concern_scores$groups,
                 p.adjust.method = "BH", pool.sd = FALSE)
```
##fishing operations
```{r}
fo.av<-aov(fishing_ops ~ groups, data = concern_scores)
summary(fo.av)

TukeyHSD(fo.av)

#test anova assumptions
#homogenity of variance
#levene test for homogenity of variance
leveneTest(fishing_ops ~ groups, data = concern_scores)

#Normality
plot(fo.av, 2)

#shapiro-wilk test to test for normality
# Extract the residuals
aov_residuals <- residuals(object = fo.av)
# Run Shapiro-Wilk test
shapiro.test(x = aov_residuals)

#variance is not homogenious but normality is fine
#use welch one way test and pairwise t-test

oneway.test(fishing_ops ~ groups, data = concern_scores)

pairwise.t.test(concern_scores$fishing_ops, concern_scores$groups,
                 p.adjust.method = "BH", pool.sd = FALSE)
```
##community and infrastructure
```{r}
cai.av<-aov(community_infras ~ groups, data = concern_scores)
summary(cai.av)

TukeyHSD(cai.av)

#test anova assumptions
#homogenity of variance
#levene test for homogenity of variance
leveneTest(community_infras ~ groups, data = concern_scores)

#Normality
plot(cai.av, 2)

#shapiro-wilk test to test for normality
# Extract the residuals
aov_residuals <- residuals(object = cai.av)
# Run Shapiro-Wilk test
shapiro.test(x = aov_residuals)

#variance is not homogenious but normality is fine
#use welch one way test and pairwise t-test

oneway.test(community_infras ~ groups, data = concern_scores)

pairwise.t.test(concern_scores$community_infras, concern_scores$groups,
                 p.adjust.method = "BH", pool.sd = FALSE)
```

##personal
```{r}
per.av<-aov(personal ~ groups, data = concern_scores)
summary(per.av)

TukeyHSD(per.av)

#test anova assumptions
#homogenity of variance
#levene test for homogenity of variance
leveneTest(personal ~ groups, data = concern_scores)

#Normality
plot(per.av, 2)

#shapiro-wilk test to test for normality
# Extract the residuals
aov_residuals <- residuals(object = per.av)
# Run Shapiro-Wilk test
shapiro.test(x = aov_residuals)

#variance is not homogenious but normality is fine
#use welch one way test and pairwise t-test

oneway.test(personal ~ groups, data = concern_scores)

pairwise.t.test(concern_scores$personal, concern_scores$groups,
                 p.adjust.method = "BH", pool.sd = FALSE)
```

##conflict
```{r}
con.av<-aov(conflict ~ groups, data = concern_scores)
summary(con.av)

TukeyHSD(con.av)

#test anova assumptions
#homogenity of variance
#levene test for homogenity of variance
leveneTest(conflict ~ groups, data = concern_scores)

#Normality
plot(con.av, 2)

#shapiro-wilk test to test for normality
# Extract the residuals
aov_residuals <- residuals(object = con.av)
# Run Shapiro-Wilk test
shapiro.test(x = aov_residuals)

#variance is not homogenious but normality is fine
#use welch one way test and pairwise t-test

oneway.test(conflict ~ groups, data = concern_scores)

pairwise.t.test(concern_scores$conflict, concern_scores$groups,
                 p.adjust.method = "BH", pool.sd = FALSE)

kruskal.test(conflict ~ groups, data = concern_scores)
```

##outlook
```{r}
out.av<-aov(outlook ~ groups, data = concern_scores)
summary(out.av)

TukeyHSD(out.av)

#test anova assumptions
#homogenity of variance
#levene test for homogenity of variance
leveneTest(outlook ~ groups, data = concern_scores)

#Normality
plot(out.av, 2)

#shapiro-wilk test to test for normality
# Extract the residuals
aov_residuals <- residuals(object = out.av)
# Run Shapiro-Wilk test
shapiro.test(x = aov_residuals)

#variance is not homogenious but normality is fine
#use welch one way test and pairwise t-test

oneway.test(outlook ~ groups, data = concern_scores)

pairwise.t.test(concern_scores$outlook, concern_scores$groups,
                 p.adjust.method = "BH", pool.sd = FALSE)

kruskal.test(outlook ~ groups, data = concern_scores)
```

##anova and tukey between clusters and themes to check for differences
```{r}
aov(environment ~ groups, data = concern_scores_rescaled)
aov('fishing ops' ~ groups, data = concern_scores_rescaled)
aov('community and infrastructure' ~ groups, data = concern_scores_rescaled)
aov(personal ~ groups, data = concern_scores_rescaled)
aov(conflict ~ groups, data = concern_scores_rescaled)
aov(outlook ~ groups, data = concern_scores_rescaled)

#test anova assumptions

#levene test for homogenity of variance
leveneTest(environment ~ groups, data = concern_scores_rescaled)
leveneTest('fishing ops' ~ groups, data = concern_scores_rescaled)
leveneTest('community and infrastructure' ~ groups, data = concern_scores_rescaled)
leveneTest(personal ~ groups, data = concern_scores_rescaled)
leveneTest(conflict ~ groups, data = concern_scores_rescaled)
leveneTest(outlook ~ groups, data = concern_scores_rescaled)

#shapiro-wilk test to test for normality
# Extract the residuals
aov_residuals <- residuals(object = res.aov )
# Run Shapiro-Wilk test
shapiro.test(x = aov_residuals )
```

#what if we do factor analysis on all the responses instead of grouping by theme
```{r}
parallel <- fa.parallel(worries,fm="minres",fa='fa')

```
